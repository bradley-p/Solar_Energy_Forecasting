{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pickle\n",
    "import math\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(5259, 34)\n(5259,)\n"
     ]
    }
   ],
   "source": [
    "data_filename = '/Users/brad/Desktop/CS6620/Project/Data/dataVersion1.npy' \n",
    "truth_filename = '/Users/brad/Desktop/CS6620/Project/Data/truthVersion1.npy' \n",
    "x = np.load(data_filename)\n",
    "y = np.load(truth_filename)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(34,)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4470, 34)\n(4470, 1)\n(789, 34)\n(789, 1)\n"
     ]
    }
   ],
   "source": [
    "train_length = int(x.shape[0] * 0.85)\n",
    "x_train = x[0 : train_length].reshape(-1, 34)\n",
    "y_train = y[0 : train_length].reshape(-1, 1)\n",
    "x_test = x[train_length : ].reshape(-1, 34)\n",
    "y_test = y[train_length : ].reshape(-1, 1)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "38702dcb823f43d4866502a18cbcba5e"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(y_train, edgecolor='black', linewidth=1)\n",
    "plt.title(\"Training data\")\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.ylabel(\"Occurences\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a964a8f2badd4a01bf35d988f94365c9"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(y_test, edgecolor='black', linewidth=1)\n",
    "plt.title(\"Validation data\")\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.ylabel(\"Occurences\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes an R^2 (goodness of fit) approximation \n",
    "def coeff_determination(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred )) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=34, activation='relu')) # for ann models \n",
    "# model.add(LSTM(128, input_shape=(34,1), return_sequences=True))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "# optimizer \n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.05, decay=1e-5)\n",
    "# compile\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=[coeff_determination])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(34,1), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "# optimizer \n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-5)\n",
    "# compile\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=[coeff_determination])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "  plt.figure()\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  plt.show()\n",
    "  plt.figure()\n",
    "  plt.plot(history.history['coeff_determination'], label='R^2')\n",
    "  plt.plot(history.history['val_coeff_determination'], label='validation R^2')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('R^2')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "34/250\n",
      "298/298 [==============================] - 0s 706us/step - loss: 0.0721 - coeff_determination: -1.3128 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 135/250\n",
      "298/298 [==============================] - 0s 713us/step - loss: 0.0737 - coeff_determination: -1.3114 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 136/250\n",
      "298/298 [==============================] - 0s 716us/step - loss: 0.0733 - coeff_determination: -1.3482 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 137/250\n",
      "298/298 [==============================] - 0s 719us/step - loss: 0.0695 - coeff_determination: -1.2990 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 138/250\n",
      "298/298 [==============================] - 0s 707us/step - loss: 0.0715 - coeff_determination: -1.3870 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 139/250\n",
      "298/298 [==============================] - 0s 730us/step - loss: 0.0746 - coeff_determination: -1.3843 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 140/250\n",
      "298/298 [==============================] - 0s 709us/step - loss: 0.0713 - coeff_determination: -1.3635 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 141/250\n",
      "298/298 [==============================] - 0s 704us/step - loss: 0.0692 - coeff_determination: -1.3262 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 142/250\n",
      "298/298 [==============================] - 0s 717us/step - loss: 0.0711 - coeff_determination: -1.3499 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 143/250\n",
      "298/298 [==============================] - 0s 715us/step - loss: 0.0705 - coeff_determination: -1.3860 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 144/250\n",
      "298/298 [==============================] - 0s 746us/step - loss: 0.0711 - coeff_determination: -1.2897 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 145/250\n",
      "298/298 [==============================] - 0s 707us/step - loss: 0.0735 - coeff_determination: -1.2919 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 146/250\n",
      "298/298 [==============================] - 0s 713us/step - loss: 0.0736 - coeff_determination: -1.3127 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 147/250\n",
      "298/298 [==============================] - 0s 713us/step - loss: 0.0740 - coeff_determination: -1.2701 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 148/250\n",
      "298/298 [==============================] - 0s 710us/step - loss: 0.0726 - coeff_determination: -1.3038 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 149/250\n",
      "298/298 [==============================] - 0s 715us/step - loss: 0.0723 - coeff_determination: -1.2889 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 150/250\n",
      "298/298 [==============================] - 0s 707us/step - loss: 0.0675 - coeff_determination: -1.3254 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 151/250\n",
      "298/298 [==============================] - 0s 718us/step - loss: 0.0729 - coeff_determination: -1.2987 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 152/250\n",
      "298/298 [==============================] - 0s 709us/step - loss: 0.0701 - coeff_determination: -1.3300 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 153/250\n",
      "298/298 [==============================] - 0s 707us/step - loss: 0.0738 - coeff_determination: -1.2728 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 154/250\n",
      "298/298 [==============================] - 0s 700us/step - loss: 0.0706 - coeff_determination: -1.4584 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 155/250\n",
      "298/298 [==============================] - 0s 711us/step - loss: 0.0706 - coeff_determination: -1.3767 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 156/250\n",
      "298/298 [==============================] - 0s 712us/step - loss: 0.0706 - coeff_determination: -1.3433 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 157/250\n",
      "298/298 [==============================] - 0s 711us/step - loss: 0.0697 - coeff_determination: -1.3117 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 158/250\n",
      "298/298 [==============================] - 0s 719us/step - loss: 0.0703 - coeff_determination: -1.3581 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 159/250\n",
      "298/298 [==============================] - 0s 716us/step - loss: 0.0697 - coeff_determination: -1.3546 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 160/250\n",
      "298/298 [==============================] - 0s 708us/step - loss: 0.0746 - coeff_determination: -1.3228 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 161/250\n",
      "298/298 [==============================] - 0s 750us/step - loss: 0.0759 - coeff_determination: -1.3476 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 162/250\n",
      "298/298 [==============================] - 0s 805us/step - loss: 0.0682 - coeff_determination: -1.3392 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 163/250\n",
      "298/298 [==============================] - 0s 697us/step - loss: 0.0697 - coeff_determination: -1.3647 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 164/250\n",
      "298/298 [==============================] - 0s 692us/step - loss: 0.0745 - coeff_determination: -1.3215 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 165/250\n",
      "298/298 [==============================] - 0s 689us/step - loss: 0.0694 - coeff_determination: -1.3231 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 166/250\n",
      "298/298 [==============================] - 0s 711us/step - loss: 0.0711 - coeff_determination: -1.3175 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 167/250\n",
      "298/298 [==============================] - 0s 698us/step - loss: 0.0680 - coeff_determination: -1.3255 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 168/250\n",
      "298/298 [==============================] - 0s 683us/step - loss: 0.0703 - coeff_determination: -1.3415 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 169/250\n",
      "298/298 [==============================] - 0s 690us/step - loss: 0.0713 - coeff_determination: -1.3112 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 170/250\n",
      "298/298 [==============================] - 0s 702us/step - loss: 0.0715 - coeff_determination: -1.2862 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 171/250\n",
      "298/298 [==============================] - 0s 779us/step - loss: 0.0717 - coeff_determination: -1.3645 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 172/250\n",
      "298/298 [==============================] - 0s 757us/step - loss: 0.0696 - coeff_determination: -1.3718 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 173/250\n",
      "298/298 [==============================] - 0s 749us/step - loss: 0.0686 - coeff_determination: -1.3986 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 174/250\n",
      "298/298 [==============================] - 0s 678us/step - loss: 0.0667 - coeff_determination: -1.3392 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 175/250\n",
      "298/298 [==============================] - 0s 698us/step - loss: 0.0712 - coeff_determination: -1.3649 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 176/250\n",
      "298/298 [==============================] - 0s 737us/step - loss: 0.0724 - coeff_determination: -1.2662 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 177/250\n",
      "298/298 [==============================] - 0s 880us/step - loss: 0.0725 - coeff_determination: -1.3165 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 178/250\n",
      "298/298 [==============================] - 0s 770us/step - loss: 0.0730 - coeff_determination: -1.2695 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 179/250\n",
      "298/298 [==============================] - 0s 773us/step - loss: 0.0691 - coeff_determination: -1.3356 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 180/250\n",
      "298/298 [==============================] - 0s 847us/step - loss: 0.0737 - coeff_determination: -1.3292 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 181/250\n",
      "298/298 [==============================] - 0s 939us/step - loss: 0.0695 - coeff_determination: -1.3717 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 182/250\n",
      "298/298 [==============================] - 0s 697us/step - loss: 0.0716 - coeff_determination: -1.3340 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 183/250\n",
      "298/298 [==============================] - 0s 775us/step - loss: 0.0726 - coeff_determination: -1.4128 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 184/250\n",
      "298/298 [==============================] - 0s 707us/step - loss: 0.0683 - coeff_determination: -1.2586 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 185/250\n",
      "298/298 [==============================] - 0s 718us/step - loss: 0.0715 - coeff_determination: -1.3366 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 186/250\n",
      "298/298 [==============================] - 0s 701us/step - loss: 0.0720 - coeff_determination: -1.3017 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 187/250\n",
      "298/298 [==============================] - 0s 901us/step - loss: 0.0688 - coeff_determination: -1.3831 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 188/250\n",
      "298/298 [==============================] - 0s 811us/step - loss: 0.0691 - coeff_determination: -1.3575 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 189/250\n",
      "298/298 [==============================] - 0s 843us/step - loss: 0.0696 - coeff_determination: -1.3267 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 190/250\n",
      "298/298 [==============================] - 0s 828us/step - loss: 0.0734 - coeff_determination: -1.3066 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 191/250\n",
      "298/298 [==============================] - 0s 728us/step - loss: 0.0706 - coeff_determination: -1.2591 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 192/250\n",
      "298/298 [==============================] - 0s 704us/step - loss: 0.0707 - coeff_determination: -1.3290 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 193/250\n",
      "298/298 [==============================] - 0s 729us/step - loss: 0.0681 - coeff_determination: -1.3459 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 194/250\n",
      "298/298 [==============================] - 0s 721us/step - loss: 0.0729 - coeff_determination: -1.3767 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 195/250\n",
      "298/298 [==============================] - 0s 706us/step - loss: 0.0706 - coeff_determination: -1.3360 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 196/250\n",
      "298/298 [==============================] - 0s 706us/step - loss: 0.0736 - coeff_determination: -1.3649 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 197/250\n",
      "298/298 [==============================] - 0s 690us/step - loss: 0.0706 - coeff_determination: -1.3196 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 198/250\n",
      "298/298 [==============================] - 0s 716us/step - loss: 0.0721 - coeff_determination: -1.3873 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 199/250\n",
      "298/298 [==============================] - 0s 702us/step - loss: 0.0726 - coeff_determination: -1.3488 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 200/250\n",
      "298/298 [==============================] - 0s 686us/step - loss: 0.0721 - coeff_determination: -1.2798 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 201/250\n",
      "298/298 [==============================] - 0s 723us/step - loss: 0.0729 - coeff_determination: -1.3276 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 202/250\n",
      "298/298 [==============================] - 0s 709us/step - loss: 0.0706 - coeff_determination: -1.3041 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 203/250\n",
      "298/298 [==============================] - 0s 730us/step - loss: 0.0724 - coeff_determination: -1.3415 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 204/250\n",
      "298/298 [==============================] - 0s 753us/step - loss: 0.0677 - coeff_determination: -1.3440 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 205/250\n",
      "298/298 [==============================] - 0s 749us/step - loss: 0.0705 - coeff_determination: -1.3071 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 206/250\n",
      "298/298 [==============================] - 0s 731us/step - loss: 0.0702 - coeff_determination: -1.3435 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 207/250\n",
      "298/298 [==============================] - 0s 756us/step - loss: 0.0710 - coeff_determination: -1.3170 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 208/250\n",
      "298/298 [==============================] - 0s 696us/step - loss: 0.0728 - coeff_determination: -1.3097 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 209/250\n",
      "298/298 [==============================] - 0s 751us/step - loss: 0.0723 - coeff_determination: -1.2902 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 210/250\n",
      "298/298 [==============================] - 0s 981us/step - loss: 0.0719 - coeff_determination: -1.3027 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 211/250\n",
      "298/298 [==============================] - 0s 701us/step - loss: 0.0689 - coeff_determination: -1.3090 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 212/250\n",
      "298/298 [==============================] - 0s 686us/step - loss: 0.0665 - coeff_determination: -1.3196 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 213/250\n",
      "298/298 [==============================] - 0s 704us/step - loss: 0.0704 - coeff_determination: -1.2770 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 214/250\n",
      "298/298 [==============================] - 0s 692us/step - loss: 0.0691 - coeff_determination: -1.4051 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 215/250\n",
      "298/298 [==============================] - 0s 690us/step - loss: 0.0687 - coeff_determination: -1.3703 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 216/250\n",
      "298/298 [==============================] - 0s 726us/step - loss: 0.0716 - coeff_determination: -1.4234 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 217/250\n",
      "298/298 [==============================] - 0s 687us/step - loss: 0.0722 - coeff_determination: -1.3144 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 218/250\n",
      "298/298 [==============================] - 0s 700us/step - loss: 0.0710 - coeff_determination: -1.2885 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 219/250\n",
      "298/298 [==============================] - 0s 700us/step - loss: 0.0696 - coeff_determination: -1.2942 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 220/250\n",
      "298/298 [==============================] - 0s 712us/step - loss: 0.0688 - coeff_determination: -1.3536 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 221/250\n",
      "298/298 [==============================] - 0s 699us/step - loss: 0.0683 - coeff_determination: -1.3876 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 222/250\n",
      "298/298 [==============================] - 0s 695us/step - loss: 0.0727 - coeff_determination: -1.2768 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 223/250\n",
      "298/298 [==============================] - 0s 705us/step - loss: 0.0707 - coeff_determination: -1.3039 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 224/250\n",
      "298/298 [==============================] - 0s 696us/step - loss: 0.0738 - coeff_determination: -1.3684 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 225/250\n",
      "298/298 [==============================] - 0s 703us/step - loss: 0.0694 - coeff_determination: -1.3342 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 226/250\n",
      "298/298 [==============================] - 0s 736us/step - loss: 0.0756 - coeff_determination: -1.2990 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 227/250\n",
      "298/298 [==============================] - 0s 705us/step - loss: 0.0747 - coeff_determination: -1.3068 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 228/250\n",
      "298/298 [==============================] - 0s 710us/step - loss: 0.0719 - coeff_determination: -1.3152 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 229/250\n",
      "298/298 [==============================] - 0s 683us/step - loss: 0.0714 - coeff_determination: -1.2817 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 230/250\n",
      "298/298 [==============================] - 0s 700us/step - loss: 0.0675 - coeff_determination: -1.3138 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 231/250\n",
      "298/298 [==============================] - 0s 708us/step - loss: 0.0700 - coeff_determination: -1.3101 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 232/250\n",
      "298/298 [==============================] - 0s 696us/step - loss: 0.0682 - coeff_determination: -1.4299 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 233/250\n",
      "298/298 [==============================] - 0s 710us/step - loss: 0.0735 - coeff_determination: -1.3452 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 234/250\n",
      "298/298 [==============================] - 0s 698us/step - loss: 0.0734 - coeff_determination: -1.3227 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 235/250\n",
      "298/298 [==============================] - 0s 750us/step - loss: 0.0675 - coeff_determination: -1.3353 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 236/250\n",
      "298/298 [==============================] - 0s 690us/step - loss: 0.0698 - coeff_determination: -1.3741 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 237/250\n",
      "298/298 [==============================] - 0s 706us/step - loss: 0.0720 - coeff_determination: -1.3775 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 238/250\n",
      "298/298 [==============================] - 0s 696us/step - loss: 0.0723 - coeff_determination: -1.3725 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 239/250\n",
      "298/298 [==============================] - 0s 695us/step - loss: 0.0753 - coeff_determination: -1.3135 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 240/250\n",
      "298/298 [==============================] - 0s 703us/step - loss: 0.0703 - coeff_determination: -1.3096 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 241/250\n",
      "298/298 [==============================] - 0s 713us/step - loss: 0.0715 - coeff_determination: -1.3227 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 242/250\n",
      "298/298 [==============================] - 0s 687us/step - loss: 0.0741 - coeff_determination: -1.3784 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 243/250\n",
      "298/298 [==============================] - 0s 695us/step - loss: 0.0735 - coeff_determination: -1.3320 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 244/250\n",
      "298/298 [==============================] - 0s 693us/step - loss: 0.0725 - coeff_determination: -1.3695 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 245/250\n",
      "298/298 [==============================] - 0s 750us/step - loss: 0.0683 - coeff_determination: -1.3686 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 246/250\n",
      "298/298 [==============================] - 0s 700us/step - loss: 0.0733 - coeff_determination: -1.3329 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 247/250\n",
      "298/298 [==============================] - 0s 687us/step - loss: 0.0741 - coeff_determination: -1.3301 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 248/250\n",
      "298/298 [==============================] - 0s 695us/step - loss: 0.0724 - coeff_determination: -1.3419 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 249/250\n",
      "298/298 [==============================] - 0s 700us/step - loss: 0.0711 - coeff_determination: -1.2976 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n",
      "Epoch 250/250\n",
      "298/298 [==============================] - 0s 711us/step - loss: 0.0702 - coeff_determination: -1.2917 - val_loss: 0.0163 - val_coeff_determination: -3.8456\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53ea930aa4374ea5a0c3126685da13c8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6422e2609ce24ce289cc651be72347bf"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "history= model.fit(x=x_train, y=y_train, batch_size=15, epochs=250, validation_data=(x_test, y_test))\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d1a221abdf89462b8f9734c5f9e96798"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1896e881a1840c49ef7102331b98d9a"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.11360767\n0.030004727349974485\n"
     ]
    }
   ],
   "source": [
    "print(preds[4][0])\n",
    "print(y_test[40][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAverageError(pred, y):\n",
    "    err = []\n",
    "    for i in range(len(pred)):\n",
    "        err.append(abs((y[i] - pred[i][0])/y[i][0]))\n",
    "\n",
    "    return sum(err)/ len(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1.25671689])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "computeAverageError(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.2078017378450374"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "preds2 = model.predict(x_train)\n",
    "computeAverageError(preds2, y_train)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "81a19aeabc6e49cab2b54c2ae52abe5b"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(x=np.arange(len(y_train)), y=y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "519b1e6b7cdf42928e24f1607c7e4544"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(x=np.arange(len(y_train)), y=preds2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}